# inference-perf/values.yaml
job:
  image:
    repository: quay.io/inference-perf/inference-perf
    tag: "" # Defaults to .Chart.AppVersion
  nodeSelector: {}
  serviceAccountName: "workload-identity-sa"
  # Example resources:
  # resources:
  #   requests:
  #     cpu: "1"
  #     memory: "4Gi"
  #   limits:
  #     cpu: "2"
  #     memory: "8Gi"
  resources:
    requests:
      cpu: "1"
      memory: "64Gi"
      ephemeral-storage: "240Gi"
    limits:
      cpu: "2"
      memory: "64Gi"
      ephemeral-storage: "240Gi"

logLevel: INFO

# A GCS bucket path that points to the dataset file.
# The file will be copied from this path to the local file system
# at /gcsDataset/gcs-dataset.json for use during the run.
# NOTE: For this dataset to be used, config.data.path must also be explicitly set to /gcsDataset/gcs-dataset.json.
# Format: bucket-name/folder/to/dataset/file
gcsPath: ""

# An S3 bucket path that points to the dataset file.
# The file will be copied from this path to the local file system
# at /s3Dataset/s3-dataset.json for use during the run.
# NOTE: For this dataset to be used, config.data.path must also be explicitly set to /s3Dataset/s3-dataset.json.
# Format: bucket-name/folder/to/dataset/file
s3Path: ""

# Optional Token configuration for Hugging Face authentication.
# hfSecret: Configures a pre-existing Kubernetes Secret.
# hfToken: Creates a new kubernetes secret with the specified token.
# If both specified, 'hfSecret' takes precedence over 'hfToken'.
token:
  hfSecret:
    name: "llm-d-hf-token" # The name of the existing Secret (e.g., 'my-hf-secret').
    key: "HF_TOKEN"  # The key within the Secret that holds the token value (e.g., 'token' or 'hf-token').

config:
  load:
    type: constant
    interval: 20
    stages:
      - rate: 1
        duration: 120
      - rate: 10
        duration: 120
      - rate: 25
        duration: 120
      - rate: 50
        duration: 120
      - rate: 100
        duration: 120
      - rate: 200
        duration: 120
    worker_max_concurrency: 1500
  api:
    type: completion
    streaming: true
  server:
    type: vllm
    model_name: unsloth/gpt-oss-120b-BF16
    base_url: http://35.209.55.248
    ignore_eos: true
  data:
    type: shared_prefix
    shared_prefix:
      num_groups: 15
      num_prompts_per_group: 6000
      system_prompt_len: 7680
      question_len: 256
      output_len: 64
  metrics:
    type: prometheus
    prometheus:
      google_managed: true
  report:
    request_lifecycle:
      summary: true
      per_stage: true
#      per_request: true
    prometheus:
      summary: true
      per_stage: true
  storage:
    local_storage:
      path: llm-d-report-v2
    google_cloud_storage:
      bucket_name: edwinhernandez-llm-d-perf
      path: llm-d-report-v2

